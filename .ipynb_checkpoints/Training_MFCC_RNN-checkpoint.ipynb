{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tiger/anaconda3/lib/python3.6/importlib/_bootstrap.py:205: RuntimeWarning: compiletime version 3.5 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.6\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import librosa\n",
    "import librosa.display\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from Data_Processing import load_data, one_hot_encode\n",
    "from Plotting import plt_confusion\n",
    "from w_initialization import xavier_weight_init\n",
    "%matplotlib inline\n",
    "plt.style.use('ggplot')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "parent_dir = \"./UrbanSound8K/audio/\"\n",
    "file_title = \"mfcc_f\"\n",
    "train_folds = np.array(range(1,9)) #first 8 folds as training set\n",
    "dev_folds = np.array([9]) #9th fold as dev set\n",
    "test_folds = np.array([10]) #10th fold as test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done!\n"
     ]
    }
   ],
   "source": [
    "train_pd, dev_pd, test_pd = load_data(parent_dir, file_title, train_folds, dev_folds, test_folds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(44074, 822)\n",
      "(5149, 822)\n",
      "(5248, 822)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>812</th>\n",
       "      <th>813</th>\n",
       "      <th>814</th>\n",
       "      <th>815</th>\n",
       "      <th>816</th>\n",
       "      <th>817</th>\n",
       "      <th>818</th>\n",
       "      <th>819</th>\n",
       "      <th>label</th>\n",
       "      <th>labels_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-601.794508</td>\n",
       "      <td>41.197002</td>\n",
       "      <td>32.010842</td>\n",
       "      <td>22.115515</td>\n",
       "      <td>15.141883</td>\n",
       "      <td>11.440791</td>\n",
       "      <td>8.947506</td>\n",
       "      <td>5.785342</td>\n",
       "      <td>1.935895</td>\n",
       "      <td>-1.268943</td>\n",
       "      <td>...</td>\n",
       "      <td>1.168137</td>\n",
       "      <td>-0.830100</td>\n",
       "      <td>-0.881071</td>\n",
       "      <td>0.440565</td>\n",
       "      <td>2.022867</td>\n",
       "      <td>2.756466</td>\n",
       "      <td>2.261087</td>\n",
       "      <td>0.978583</td>\n",
       "      <td>3</td>\n",
       "      <td>dog_bark</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-464.533934</td>\n",
       "      <td>64.617082</td>\n",
       "      <td>16.303920</td>\n",
       "      <td>-1.111503</td>\n",
       "      <td>-0.433955</td>\n",
       "      <td>1.262720</td>\n",
       "      <td>7.620899</td>\n",
       "      <td>10.542473</td>\n",
       "      <td>6.174512</td>\n",
       "      <td>4.805861</td>\n",
       "      <td>...</td>\n",
       "      <td>1.162675</td>\n",
       "      <td>10.263624</td>\n",
       "      <td>17.193635</td>\n",
       "      <td>16.461270</td>\n",
       "      <td>9.028572</td>\n",
       "      <td>-0.038945</td>\n",
       "      <td>-7.037274</td>\n",
       "      <td>-10.866433</td>\n",
       "      <td>3</td>\n",
       "      <td>dog_bark</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-516.651693</td>\n",
       "      <td>19.968049</td>\n",
       "      <td>17.275986</td>\n",
       "      <td>14.921056</td>\n",
       "      <td>14.084322</td>\n",
       "      <td>14.303494</td>\n",
       "      <td>14.015374</td>\n",
       "      <td>12.095609</td>\n",
       "      <td>8.955372</td>\n",
       "      <td>6.183448</td>\n",
       "      <td>...</td>\n",
       "      <td>5.386635</td>\n",
       "      <td>3.724471</td>\n",
       "      <td>1.776935</td>\n",
       "      <td>-0.222573</td>\n",
       "      <td>-1.957162</td>\n",
       "      <td>-3.135341</td>\n",
       "      <td>-3.606978</td>\n",
       "      <td>-3.428243</td>\n",
       "      <td>3</td>\n",
       "      <td>dog_bark</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-611.038601</td>\n",
       "      <td>152.679036</td>\n",
       "      <td>7.694100</td>\n",
       "      <td>6.090352</td>\n",
       "      <td>-9.180392</td>\n",
       "      <td>-5.429061</td>\n",
       "      <td>-2.109360</td>\n",
       "      <td>6.013322</td>\n",
       "      <td>-9.527831</td>\n",
       "      <td>8.372993</td>\n",
       "      <td>...</td>\n",
       "      <td>-3.812518</td>\n",
       "      <td>-10.145887</td>\n",
       "      <td>-6.123251</td>\n",
       "      <td>8.423540</td>\n",
       "      <td>6.449011</td>\n",
       "      <td>7.272332</td>\n",
       "      <td>0.495488</td>\n",
       "      <td>10.595652</td>\n",
       "      <td>3</td>\n",
       "      <td>dog_bark</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-520.054010</td>\n",
       "      <td>19.747304</td>\n",
       "      <td>18.052447</td>\n",
       "      <td>15.725482</td>\n",
       "      <td>13.307161</td>\n",
       "      <td>11.234205</td>\n",
       "      <td>9.690698</td>\n",
       "      <td>8.574254</td>\n",
       "      <td>7.585095</td>\n",
       "      <td>6.392648</td>\n",
       "      <td>...</td>\n",
       "      <td>-6.215439</td>\n",
       "      <td>-7.080674</td>\n",
       "      <td>-13.379082</td>\n",
       "      <td>10.117200</td>\n",
       "      <td>-1.067749</td>\n",
       "      <td>0.439238</td>\n",
       "      <td>-5.649780</td>\n",
       "      <td>-0.733906</td>\n",
       "      <td>3</td>\n",
       "      <td>dog_bark</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 822 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            0           1          2          3          4          5  \\\n",
       "0 -601.794508   41.197002  32.010842  22.115515  15.141883  11.440791   \n",
       "1 -464.533934   64.617082  16.303920  -1.111503  -0.433955   1.262720   \n",
       "2 -516.651693   19.968049  17.275986  14.921056  14.084322  14.303494   \n",
       "3 -611.038601  152.679036   7.694100   6.090352  -9.180392  -5.429061   \n",
       "4 -520.054010   19.747304  18.052447  15.725482  13.307161  11.234205   \n",
       "\n",
       "           6          7         8         9     ...            812        813  \\\n",
       "0   8.947506   5.785342  1.935895 -1.268943     ...       1.168137  -0.830100   \n",
       "1   7.620899  10.542473  6.174512  4.805861     ...       1.162675  10.263624   \n",
       "2  14.015374  12.095609  8.955372  6.183448     ...       5.386635   3.724471   \n",
       "3  -2.109360   6.013322 -9.527831  8.372993     ...      -3.812518 -10.145887   \n",
       "4   9.690698   8.574254  7.585095  6.392648     ...      -6.215439  -7.080674   \n",
       "\n",
       "         814        815       816       817       818        819  label  \\\n",
       "0  -0.881071   0.440565  2.022867  2.756466  2.261087   0.978583      3   \n",
       "1  17.193635  16.461270  9.028572 -0.038945 -7.037274 -10.866433      3   \n",
       "2   1.776935  -0.222573 -1.957162 -3.135341 -3.606978  -3.428243      3   \n",
       "3  -6.123251   8.423540  6.449011  7.272332  0.495488  10.595652      3   \n",
       "4 -13.379082  10.117200 -1.067749  0.439238 -5.649780  -0.733906      3   \n",
       "\n",
       "   labels_name  \n",
       "0     dog_bark  \n",
       "1     dog_bark  \n",
       "2     dog_bark  \n",
       "3     dog_bark  \n",
       "4     dog_bark  \n",
       "\n",
       "[5 rows x 822 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(train_pd.shape)\n",
    "print(dev_pd.shape)\n",
    "print(test_pd.shape)\n",
    "train_pd.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x, train_y = train_pd.iloc[:, 0:820].values, train_pd.iloc[:, 820].values\n",
    "dev_x, dev_y = dev_pd.iloc[:, 0:820].values, dev_pd.iloc[:, 820].values\n",
    "test_x, test_y = test_pd.iloc[:, 0:820].values, test_pd.iloc[:, 820].values\n",
    "\n",
    "train_x = train_x.reshape(train_x.shape[0], 41, 20)\n",
    "dev_x = dev_x.reshape(dev_x.shape[0], 41, 20)\n",
    "test_x = test_x.reshape(test_x.shape[0], 41, 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_y_one_hot = one_hot_encode(train_y)\n",
    "dev_y_one_hot = one_hot_encode(dev_y)\n",
    "test_y_one_hot = one_hot_encode(test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(44074, 41, 20)\n"
     ]
    }
   ],
   "source": [
    "print(train_x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "learning_rate = 0.01 #learning rate\n",
    "training_iters = 10000 #number of epoch\n",
    "batch_size = 128 #mini_batch gradient descent\n",
    "display_step = 400\n",
    "\n",
    "# Network Parameters\n",
    "n_input = 20 \n",
    "n_steps = 41 #number of RNN steps\n",
    "n_hidden = 300 #number of hidden units\n",
    "n_classes = 10 \n",
    "\n",
    "lamb_final = 0.02\n",
    "\n",
    "x = tf.placeholder(\"float\", [None, n_steps, n_input])\n",
    "y = tf.placeholder(\"float\", [None, n_classes])\n",
    "\n",
    "#full connected layer\n",
    "weight_initializer = xavier_weight_init()\n",
    "weight = tf.Variable(weight_initializer((n_hidden, n_classes)))\n",
    "bias = tf.Variable(tf.random_normal([n_classes]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#RNN layers consist of 2 layers of LSTM\n",
    "def RNN(x, weight, bias):\n",
    "    cell = tf.contrib.rnn.MultiRNNCell([tf.contrib.rnn.LSTMCell(n_hidden, state_is_tuple = True) for _ in range(2)])\n",
    "    output, state = tf.nn.dynamic_rnn(cell, x, dtype = tf.float32)\n",
    "    output = tf.transpose(output, [1, 0, 2])\n",
    "    last = tf.gather(output, int(output.get_shape()[0]) - 1)\n",
    "    return tf.nn.softmax(tf.matmul(last, weight) + bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tiger/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/gradients_impl.py:96: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    }
   ],
   "source": [
    "prediction = RNN(x, weight, bias)\n",
    "\n",
    "# Define loss and optimizer, use cross entropy loss and adam optimizer\n",
    "\n",
    "loss_f = -tf.reduce_mean(y * tf.log(prediction)) + 0.5*lamb_final*(tf.nn.l2_loss(bias) + tf.nn.l2_loss(weight))\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate = learning_rate).minimize(loss_f)\n",
    "\n",
    "# Evaluate model\n",
    "correct_pred = tf.equal(tf.argmax(prediction,1), tf.argmax(y,1))\n",
    "correct_pred_count = tf.reduce_sum(tf.cast(correct_pred, tf.int32))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))\n",
    "\n",
    "# Initializing the variables\n",
    "init = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def testing(session, pred_tensor, test_x, test_y):\n",
    "    l_range = test_x.shape[0] // batch_size if test_x.shape[0] % batch_size else test_x.shape[0] // batch_size + 1\n",
    "    \n",
    "    correct = 0\n",
    "    \n",
    "    for i in range(l_range):\n",
    "        offset = (i * batch_size) % (test_x.shape[0] - batch_size)\n",
    "        \n",
    "        test_bx = test_x[offset: (offset + batch_size), :, :]\n",
    "        test_by = test_y[offset: (offset + batch_size), :]\n",
    "        \n",
    "        correct += session.run(pred_tensor, feed_dict = {x : test_bx, y : test_by})\n",
    "        \n",
    "    return float(correct)/test_x.shape[0]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 399, Minibatch Loss= 0.184643, Training Accuracy= 0.00000\n",
      "Iter 799, Minibatch Loss= 0.106582, Training Accuracy= 0.67969\n",
      "Iter 999, Minibatch Loss= 0.106582, Test Accuracy= 0.23152\n",
      "Iter 1199, Minibatch Loss= 0.273978, Training Accuracy= 0.00000\n",
      "Iter 1599, Minibatch Loss= 0.248451, Training Accuracy= 0.07031\n",
      "Iter 1999, Minibatch Loss= 0.234696, Training Accuracy= 0.14062\n",
      "Iter 1999, Minibatch Loss= 0.234696, Test Accuracy= 0.28525\n",
      "Iter 2399, Minibatch Loss= 0.199267, Training Accuracy= 0.21094\n",
      "Iter 2799, Minibatch Loss= 0.241288, Training Accuracy= 0.00000\n",
      "Iter 2999, Minibatch Loss= 0.241288, Test Accuracy= 0.22409\n",
      "Iter 3199, Minibatch Loss= 0.256359, Training Accuracy= 0.26562\n",
      "Iter 3599, Minibatch Loss= 0.121335, Training Accuracy= 0.88281\n",
      "Iter 3999, Minibatch Loss= 0.276415, Training Accuracy= 0.04688\n",
      "Iter 3999, Minibatch Loss= 0.276415, Test Accuracy= 0.11338\n",
      "Iter 4399, Minibatch Loss= 0.215573, Training Accuracy= 0.03906\n",
      "Iter 4799, Minibatch Loss= 0.146957, Training Accuracy= 0.82031\n",
      "Iter 4999, Minibatch Loss= 0.146957, Test Accuracy= 0.30716\n",
      "Iter 5199, Minibatch Loss= 0.187456, Training Accuracy= 0.70312\n",
      "Iter 5599, Minibatch Loss= 0.276646, Training Accuracy= 0.00000\n",
      "Iter 5999, Minibatch Loss= 0.165287, Training Accuracy= 0.00000\n",
      "Iter 5999, Minibatch Loss= 0.165287, Test Accuracy= 0.33594\n",
      "Iter 6399, Minibatch Loss= 0.240055, Training Accuracy= 0.00781\n",
      "Iter 6799, Minibatch Loss= 0.289511, Training Accuracy= 0.00781\n",
      "Iter 6999, Minibatch Loss= 0.289511, Test Accuracy= 0.29783\n",
      "Iter 7199, Minibatch Loss= 0.139023, Training Accuracy= 0.60156\n",
      "Iter 7599, Minibatch Loss= 0.197865, Training Accuracy= 0.22656\n",
      "Iter 7999, Minibatch Loss= 0.155659, Training Accuracy= 0.71094\n",
      "Iter 7999, Minibatch Loss= 0.155659, Test Accuracy= 0.44417\n",
      "Iter 8399, Minibatch Loss= 0.200222, Training Accuracy= 0.24219\n",
      "Iter 8799, Minibatch Loss= 0.271559, Training Accuracy= 0.01562\n",
      "Iter 8999, Minibatch Loss= 0.271559, Test Accuracy= 0.41292\n",
      "Iter 9199, Minibatch Loss= 0.162661, Training Accuracy= 0.00000\n",
      "Iter 9599, Minibatch Loss= 0.182045, Training Accuracy= 0.33594\n",
      "Iter 9999, Minibatch Loss= 0.160929, Training Accuracy= 0.63281\n",
      "Iter 9999, Minibatch Loss= 0.160929, Test Accuracy= 0.45732\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "with tf.Session() as session:\n",
    "    session.run(init)\n",
    "\n",
    "    for itr in range(training_iters):    \n",
    "        offset = (itr * batch_size) % (train_x.shape[0] - batch_size)\n",
    "        batch_x = train_x[offset:(offset + batch_size), :, :]\n",
    "        batch_y = train_y_one_hot[offset:(offset + batch_size), :]\n",
    "        _, c = session.run([optimizer, loss_f],feed_dict={x: batch_x, y : batch_y})\n",
    "            \n",
    "        if (itr+1) % display_step == 0:\n",
    "            # Calculate batch accuracy\n",
    "            acc = session.run(accuracy, feed_dict={x: batch_x, y: batch_y})\n",
    "            # Calculate batch loss\n",
    "            loss = session.run(loss_f, feed_dict={x: batch_x, y: batch_y})\n",
    "            print(\"Iter \" + str(itr) + \", Minibatch Loss= \" + \\\n",
    "                  \"{:.6f}\".format(loss)) # + \", Training Batch Accuracy= \" + \"{:.5f}\".format(acc))\n",
    "    \n",
    "        if (itr+1) % 1000 == 0:\n",
    "            test_accuracy = testing(session, correct_pred_count, test_x, test_y_one_hot)\n",
    "            print(\"Iter \" + str(itr) + \", Minibatch Loss= \" + \\\n",
    "                  \"{:.6f}\".format(loss) + \", Test Accuracy= \" + \\\n",
    "                  \"{:.5f}\".format(test_accuracy))\n",
    "\n",
    "end_time = time.time()\n",
    "print(\"seconds:\", end_time-start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4573170731707317"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
